{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sayakpaul/SimSiam-TF/blob/main/SimSiam_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spvkjI26p5hP"
   },
   "source": [
    "This notebook evaluates the frozen features of a ResNet50 pre-trained (50 epochs of pre-training) using the [SimSiam method](https://arxiv.org/abs/2011.10566). You can refer to the [pre-training notebook here](https://github.com/sayakpaul/SimSiam-TF/blob/main/SimSiam_Pre_training.ipynb). Following evaluation methods have been used - \n",
    "\n",
    "* Linear evaluation of the frozen features\n",
    "\n",
    "*Please note that to keep this minimal I did not follow the original hyperparameter configurations rigorously.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHxqoL8criDm"
   },
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjv_xR31qway",
    "outputId": "0540994e-cb2e-4e81-9b55-3c44c75bd382"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFTq1rLLpxm9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eabbJmtEqxZx"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "tf.random.set_seed(666)\n",
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pVwjqIDrbNR"
   },
   "source": [
    "## Dataset collection & preparation\n",
    "\n",
    "The following code is referred from [here](https://github.com/ayulockin/SwAV-TF/blob/master/linear_evaluation/Linear_Evaluation_10_Epochs.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mqcYr9UMrNtt",
    "outputId": "c286bf12-4f9b-43ef-d957-436831406f66"
   },
   "outputs": [],
   "source": [
    "# Gather Flowers dataset\n",
    "train_ds, validation_ds = tfds.load(\n",
    "    \"imagenet2012_subset/10pct\",\n",
    "    split=[\"train[:85%]\", \"train[85%:]\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "@tf.function\n",
    "def scale_resize_image(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, (224, 224)) # Resizing to highest resolution used while training swav\n",
    "    return (image, label)\n",
    "\n",
    "training_ds = (\n",
    "    train_ds\n",
    "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "validation_ds = (\n",
    "    validation_ds\n",
    "    .map(scale_resize_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvAOIxtruK4S"
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g91yjhLhrH41"
   },
   "outputs": [],
   "source": [
    "def get_encoder():\n",
    "    base_model = tf.keras.applications.ResNet50(include_top=False,\n",
    "        weights=None, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = True\n",
    "\n",
    "    inputs = tf.keras.layers.Input((224, 224, 3))\n",
    "    x = base_model(inputs, training=True)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(2048, activation='relu', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    z = tf.keras.layers.Dense(2048)(x)\n",
    "\n",
    "    f = tf.keras.Model(inputs, z)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFTZNOpIsSLm",
    "outputId": "e0199d8d-502c-4b22-b155-8dfc3d9a65c1"
   },
   "outputs": [],
   "source": [
    "get_encoder().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhGhjwwzr5yi",
    "outputId": "ff44cd06-e17f-411a-a43f-fcba43f8f32f"
   },
   "outputs": [],
   "source": [
    "# We now load up the pre-trained weights\n",
    "projection = get_encoder()\n",
    "projection.load_weights('ImageNet/projection_024.h5')\n",
    "\n",
    "# Create a sub-model for extracting features\n",
    "rn50 = tf.keras.Model(projection.input, projection.layers[2].output)\n",
    "rn50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbSkm4NPsecS"
   },
   "outputs": [],
   "source": [
    "def get_linear_classifier(feature_backbone, trainable=False):\n",
    "    inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "    \n",
    "    feature_backbone.trainable = trainable\n",
    "    x = feature_backbone(inputs, training=False)\n",
    "    outputs = tf.keras.layers.Dense(1000, activation=\"softmax\", )(x)\n",
    "    linear_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    return linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DP-lW-7ms7Lj",
    "outputId": "34b76e31-6f6f-48af-ff03-3e15963d51fa"
   },
   "outputs": [],
   "source": [
    "get_linear_classifier(rn50).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drzXtvV2tdjW"
   },
   "outputs": [],
   "source": [
    "def plot_progress(hist):\n",
    "    plt.plot(hist.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(hist.history[\"val_loss\"], label=\"validation_loss\")\n",
    "    plt.plot(hist.history[\"accuracy\"], label=\"training_accuracy\")\n",
    "    plt.plot(hist.history[\"val_accuracy\"], label=\"validation_accuracy\")\n",
    "    plt.title(\"Training Progress\")\n",
    "    plt.ylabel(\"accuracy/loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNAn38zSuSUV"
   },
   "source": [
    "## Linear evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBw85iBGs-Cm"
   },
   "outputs": [],
   "source": [
    "# Early Stopping to prevent overfitting\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                 patience=5, verbose=2, \n",
    "                                                 restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BxH5ImyItN59",
    "outputId": "87b90427-fe76-472c-ac3a-f6778f7758ec"
   },
   "outputs": [],
   "source": [
    "# Get linear model and compile\n",
    "tf.keras.backend.clear_session()\n",
    "model = get_linear_classifier(rn50)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"],\n",
    "                     optimizer=\"adam\")\n",
    "\n",
    "# Train \n",
    "history = model.fit(training_ds,\n",
    "                 validation_data=validation_ds,\n",
    "                 epochs=50,\n",
    "                 callbacks=[early_stopper]\n",
    "                 )\n",
    "plot_progress(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NctQf484t4GR",
    "outputId": "d1449782-c614-41ff-b5a5-6448978db53f"
   },
   "outputs": [],
   "source": [
    "_, acc = model.evaluate(validation_ds)\n",
    "print('Validation accuracy:', round(acc*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykzPyP-uyJRu"
   },
   "source": [
    "For a minimal implementation the scores aren't that bad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_progress_acc(hist):\n",
    "    fig, axs = plt.subplots(1,1, figsize=(10,6))\n",
    "    plt.plot(hist.history[\"accuracy\"], label=\"training_accuracy\")\n",
    "    plt.plot(hist.history[\"val_accuracy\"], label=\"validation_accuracy\")\n",
    "    plt.title(\"Training Progress -- Accuracy\", size=20)\n",
    "    plt.ylabel(\"accuracy\", size=20); plt.yticks(size=15)\n",
    "    plt.xlabel(\"epoch\", size=20); plt.xticks(size=15)\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def plot_progress_loss(hist):\n",
    "    fig, axs = plt.subplots(1,1, figsize=(10,6))\n",
    "    plt.plot(hist.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(hist.history[\"val_loss\"], label=\"validation_loss\")\n",
    "    plt.title(\"Training Progress -- Loss\", size=20)\n",
    "    plt.ylabel(\"loss\", size=20); plt.yticks(size=15)\n",
    "    plt.xlabel(\"epoch\", size=20); plt.xticks(size=15)\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_progress_acc(history)\n",
    "plot_progress_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMAleSaBYAAgM4+rTN5xy7y",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SimSiam_Evaluation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
